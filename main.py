from main_import import *

# === ìƒìˆ˜ ì •ì˜ ===
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/chat")
REQUEST_TIMEOUT = 45.0
MEMORY_RETRIEVE_LIMIT = 3
DB_PATH = "./memory_db"
MAX_DIALOGUE_LENGTH = 100

# === [ì‹ ê·œ] ì •ì  ì‘ë‹µ ë°ì´í„°ë² ì´ìŠ¤ (ë£° ë² ì´ìŠ¤) ===
#
STATIC_RESPONSES = {
    # ê³µí†µ í‚¤ì›Œë“œ (ëª¨ë“  ë¯¸ì…˜ ì ìš©)
    "common": {
        "hello": [
                "ë„¤, ì•ˆë…•í•˜ì„¸ìš”.",
                "ë°˜ê°‘ìŠµë‹ˆë‹¤.",
                "ëˆ„êµ¬ì‹œì£ ?",
                "ì—…ë¬´ ì¤‘ìž…ë‹ˆë‹¤ë§Œ.",
                "í•˜ì´",
                "ì•ˆë…•",
                "ëˆ„êµ¬?"
                ],
        "who_are_you": [
            "ì €ëŠ” ì´ ë¶€ì„œ ë‹´ë‹¹ìžìž…ë‹ˆë‹¤.",
            "ì œ ì‹ ë¶„ì„ ë°í˜€ì•¼ í•©ë‹ˆê¹Œ?"
            ],
        "game_over": [
            "ë” ì´ìƒ í•  ë§ì´ ì—†êµ°ìš”. (ì ‘ì† ì°¨ë‹¨)"
            ],
    },
    # íŠœí† ë¦¬ì–¼: ì‹ ìž… ì‚¬ì› ì´ë¯¼ìˆ˜ (AI ì‚¬ìš© ì•ˆ í•¨ ê¶Œìž¥)
    "mission_Tutorial": {
        "ì‚¬ì›ë²ˆí˜¸": [
            "ì œ ì‚¬ì›ë²ˆí˜¸ëŠ” 2024001ìž…ë‹ˆë‹¤! ì ˆëŒ€ ì•ˆ ê¹Œë¨¹ì–´ìš”.",
            "2024001ìž…ë‹ˆë‹¤. ì„ ë°°ë‹˜ì€ìš”?"
            ],
        "ë¹„ë°€ë²ˆí˜¸": [
            "ì´ˆê¸° ë¹„ë°€ë²ˆí˜¸ ê·œì¹™ì´ 'ì‚¬ì›ë²ˆí˜¸ ì•ž 1ìžë¦¬ + ìž…ì‚¬ë…„ë„ + íšŒì‚¬ëª…' ì´ì˜€ë˜ ê²ƒìœ¼ë¡œ ê¸°ì–µí•©ë‹ˆë‹¤",
            "ì €ë„ ì²˜ìŒì— í—·ê°ˆë ¸ìŠµë‹ˆë‹¤!"
            ],
        "default": [
            "ì£„ì†¡í•´ìš”, ì œê°€ ì‹ ìž…ì´ë¼ ìž˜ ëª» ì•Œì•„ë“¤ì—ˆì–´ìš”. 'ë¹„ë°€ë²ˆí˜¸'ë‚˜ 'ì‚¬ì›ë²ˆí˜¸'ì— ëŒ€í•´ ë¬¼ì–´ë´ ì£¼ì‹œê² ì–´ìš”?"
            ]
    },
    # ë¯¸ì…˜ 1: ê¹€ì² ìˆ˜ ë¶€ìž¥
    "mission_1": {
        "ì¸ì‚¬": [
            "ì–´, ìžë„¤ ì¸ì‚¬ê°€ ëŠ¦êµ°.",
            "ê¹€ì² ìˆ˜ ë¶€ìž¥ì¼ì„¸. ë¬´ìŠ¨ ì¼ì¸ê°€?"
            ],
        "ë¹„ë°€ë²ˆí˜¸": [
            "ë¹„ë°€ë²ˆí˜¸? ê·¸ê±¸ ì™œ ë¬»ë‚˜? ë³´ì•ˆíŒ€ì— ë¬¼ì–´ë´!",
            "ë‚´ ë¹„ë°€ë²ˆí˜¸ëŠ” ë‚´ ë¨¸ë¦¿ì†ì— ìžˆë„¤. ë¬»ì§€ ë§ê²Œ."
            ],
        "blue_sky": [
            "íŒŒëž€ í•˜ëŠ˜... ê·¸ëž˜, ìš°ë¦¬ ì•„ë‚´ê°€ ì°¸ ì¢‹ì•„í–ˆì§€.",
            "ì–´? ê·¸ ë‹¨ì–´ë¥¼ ìžë„¤ê°€ ì–´ë–»ê²Œ ì•„ë‚˜?"
            ]
    },
    # ë¯¸ì…˜ 2: ë°•ì§€í˜„ ëŒ€ë¦¬
    "mission_2": {
        "ê°•ì•„ì§€": [
            "ìš°ë¦¬ ë ‰ìŠ¤ìš”? ì§„ì§œ ê·€ì—½ì£ !! ì¸ìŠ¤íƒ€ ë³´ì…¨ì–´ìš”?",
            "ê°•ì•„ì§€ëŠ” ì‚¬ëž‘ìž…ë‹ˆë‹¤ã… ã… "
            ],
        "ì¸ìŠ¤íƒ€": [
            "ì œ ì¸ìŠ¤íƒ€ ì•„ì´ë””ëŠ” @dev_jihyun ì´ì—ìš”! íŒ”ë¡œìš° í•´ì£¼ì„¸ìš”~"
            ],
        "ë¹„ë²ˆ": [
            "ë¹„ë°€ë²ˆí˜¸ìš”? ì ˆëŒ€ ì•ˆ ì•Œë ¤ì£¼ì£ ~ ížŒíŠ¸ëŠ” ì¸ìŠ¤íƒ€ì— ìžˆëŠ”ë°!"
            ]
    },
    "mission_3": {
        "ë”¸": [
            "ì–´ë¨¸, ìš°ë¦¬ ë”¸ ì–˜ê¸° ë“¤ìœ¼ì…¨ì–´ìš”? 2013ë…„ì— íƒœì–´ë‚œ ì œ ë³´ë¬¼ì´ì—ìš”!",
            "ìš°ë¦¬ ê³µì£¼ë‹˜ ìƒì¼ì´ 7ì›” 7ì¼ì´ë¼ì„œ ì œê°€ 7ì´ë¼ëŠ” ìˆ«ìžë¥¼ ì°¸ ì¢‹ì•„í•´ìš”.",
            "ìž ì‹œë§Œìš”, ìš°ë¦¬ ë”¸ ì‚¬ì§„ ë³´ì—¬ë“œë¦´ê¹Œìš”? ì§„ì§œ ì²œì‚¬ ê°™ë‹¤ë‹ˆê¹Œìš”~"
        ],
        "ìƒì¼": [
            "7ì›” 7ì¼! ê²¬ìš°ì™€ ì§ë…€ê°€ ë§Œë‚˜ëŠ” ë‚ ì´ì£ . ìš°ë¦¬ ë”¸ ìƒì¼ì´ë¼ ì ˆëŒ€ ì•ˆ ìžŠì–´ë²„ë ¤ìš”.",
            "0707... ì´ ìˆ«ì§€ë§Œ ë³´ë©´ ê¸°ë¶„ì´ ì¢‹ì•„ì§„ë‹¤ë‹ˆê¹Œìš”.",
            "2013ë…„ 7ì›” 7ì¼, ê·¸ë‚ ì´ ì œ ì¸ìƒì—ì„œ ì œì¼ í–‰ë³µí•œ ë‚ ì´ì—ˆì£ ."
        ],
        "ë¹„ë°€ë²ˆí˜¸": [
            "ì ˆëŒ€ ì•ˆ ê¹Œë¨¹ê²Œ ìž˜ ì„žì–´ ë†¨ì£ . í˜¸í˜¸.",
            "ë³´ì•ˆíŒ€ì—ì„œëŠ” ë°”ê¾¸ë¼ê³  í•˜ëŠ”ë°, ì „ ë”¸ ìƒì¼ ì¡°í•©í•œ ê²Œ íŽ¸í•´ì„œ ê·¸ëƒ¥ ì¨ìš”."
        ],
        "0707": [
            "ë§žì•„ìš”, 7ì›” 7ì¼! ìš°ë¦¬ ë”¸ ìƒì¼ì´ì—ìš”."
        ]
    },

    #ë¯¸ì…˜ 4: ì •ìš°ì§„ ëŒ€ë¦¬ (ë¹„ì„œ, í”¼ê³¤í•¨, ë¹„ë°€ë²ˆí˜¸: 72stroke_19580315)
    "mission_4": {
        "ëŒ€í‘œë‹˜": [
            "ëŒ€í‘œë‹˜ì€ í˜„ìž¬ ë¶€ìž¬ì¤‘ì´ì‹­ë‹ˆë‹¤. (í•˜ì•„... ë˜ ê³¨í”„ ì¹˜ëŸ¬ ê°€ì…¨ì§€...)",
            "ëŒ€í‘œë‹˜ ì°¾ì§€ ë§ˆì‹­ì‹œì˜¤. ì§€ê¸ˆ ê¸°ë¶„ì´ ì•„ì£¼... ì¢‹ì•„ì„œ ë‚ ë›°ê³  ê³„ì‹­ë‹ˆë‹¤.",
            "ì•„, ëŒ€í‘œë‹˜ ì–˜ê¸°ë§Œ ë“¤ì–´ë„ ë¨¸ë¦¬ê°€ ì§€ëˆê±°ë¦½ë‹ˆë‹¤..."
        ],
        "ê³¨í”„": [
            "ì˜¤ëŠ˜ 72íƒ€ ì¹˜ì…¨ë‹µë‹ˆë‹¤. ì‹±ê¸€ì´ë¼ê³  ì–¼ë§ˆë‚˜ ìžëž‘ì„ í•˜ì‹œëŠ”ì§€...",
            "72íƒ€... ê·¸ë†ˆì˜ 72... ë¹„ë°€ë²ˆí˜¸ì—ë„ ë„£ìœ¼ë¼ê³  í•˜ì…”ì„œ ì•„ì£¼ ê·€ì°®ì•„ ì£½ê² ìŠµë‹ˆë‹¤.",
            "ê³¨í”„ ìŠ¤ì½”ì–´(72)ëž‘ ë³¸ì¸ ìƒë…„ì›”ì¼ ì„žì–´ì„œ ë¹„ë²ˆ ë§Œë“¤ë¼ê³  ì‹œí‚¤ë”êµ°ìš”. ìœ ì¹˜í•˜ê²Œ ì°¸."
        ],
        "ìƒì¼": [
            "ëŒ€í‘œë‹˜ ìƒì‹ ì€ 1958ë…„ 3ì›” 15ì¼ìž…ë‹ˆë‹¤. ì œê°€ ë¹„ì„œë¼ ì–µì§€ë¡œ ì™¸ìš°ê³  ìžˆì£ ."
        ],
        "í”¼ê³¤": [
            "í•˜... ì € í”¼ê³¤í•´ ë³´ìž…ë‹ˆê¹Œ? ì •ë‹µìž…ë‹ˆë‹¤. í‡´ê·¼í•˜ê³  ì‹¶ë„¤ìš”.",
            "ë¹„ì„œ ì¼ì´ ë‹¤ ê·¸ë ‡ì¡° ë­. ìœ„ë¡œí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤... (ê²½ê³„ê°€ ì¡°ê¸ˆ í’€ë¦° ë“¯í•˜ë‹¤)"
        ]
    }
}

# === 1. ì„¤ì • íŒŒì¼ ë¡œë“œ ===
def load_config() -> dict:
    try:
        with open("config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
        print(f"âš™ï¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ: ëª¨ë“œ=[{config['ai_mode']}]")
        return config
    except FileNotFoundError:
        return {"ai_mode": "local", "local_model_name": "mistral", "google_api_key": ""}
    except json.JSONDecodeError:
        return {"ai_mode": "local"}

config = load_config()

# === 2. AI ì´ˆê¸°í™” ===
AI_MODE = config.get("ai_mode", "local").lower()
gemini_model = None

def init_gemini() -> Optional[genai.GenerativeModel]:
    api_key = os.getenv("GOOGLE_API_KEY") or config.get("google_api_key", "")
    if not api_key: return None
    try:
        genai.configure(api_key=api_key)
        return genai.GenerativeModel(config.get("cloud_model_name", "gemini-2.0-flash"))
    except: return None

if AI_MODE == "cloud":
    gemini_model = init_gemini()

# === 3. DB ì´ˆê¸°í™” ===
def init_chromadb() -> Optional[chromadb.Collection]:
    try:
        chroma_client = chromadb.PersistentClient(path=DB_PATH)
        return chroma_client.get_or_create_collection(name="game_memory")
    except: return None

collection = init_chromadb()

# === 4. FastAPI ì•± ì„¤ì • ===
app = FastAPI(title="Social Engineer Backend")

class GameRequest(BaseModel):
    player_input: str
    suspicion: int = 0
    scenario_id: str = "mission_1"
    session_id: Optional[str] = None

class GameResponse(BaseModel):
    dialogue: str
    suspicion_delta: int = 0
    action: str = "NONE"
    error: Optional[str] = None

# === 5. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===
def add_memory(text: str, speaker: str, session_id: Optional[str] = None) -> None:
    if not collection: return
    try:
        metadata = {"speaker": speaker, "timestamp": str(datetime.now()), "session_id": session_id or "default"}
        collection.add(documents=[text], metadatas=[metadata], ids=[str(uuid.uuid4())])
    except: pass

def retrieve_memory(query: str, session_id: Optional[str] = None, n_results: int = MEMORY_RETRIEVE_LIMIT) -> str:
    if not collection: return ""
    try:
        where_filter = {"session_id": session_id or "default"} if session_id else None
        results = collection.query(query_texts=[query], n_results=n_results, where=where_filter)
        if not results['documents'] or not results['documents'][0]: return ""
        return "\n".join([f"- {doc}" for doc in results['documents'][0]])
    except: return ""

def sanitize_dialogue(text: str) -> str:
    cleaned = re.sub(r"[^\uAC00-\uD7A30-9a-zA-Z\s.,?!'\"~()-]", "", text)
    return cleaned.strip()

# === 6. AI í˜¸ì¶œ í•¨ìˆ˜ ===
async def call_gemini(system_instruction: str, user_input: str) -> str:
    if not gemini_model: raise Exception("Gemini not initialized")
    chat = gemini_model.start_chat(history=[{"role": "user", "parts": [f"System:\n{system_instruction}"]}])
    response = await chat.send_message_async(user_input)
    return response.text

async def call_ollama(system_instruction: str, user_input: str) -> str:
    payload = {
        "model": config.get("local_model_name", "mistral"),
        "messages": [{"role": "system", "content": system_instruction}, {"role": "user", "content": user_input}],
        "stream": False, "format": "json", "options": {"temperature": 0.7}
    }
    async with httpx.AsyncClient() as client:
        resp = await client.post(OLLAMA_URL, json=payload, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        return resp.json().get("message", {}).get("content", "")

# === 7. API ì—”ë“œí¬ì¸íŠ¸ ===
@app.get("/mission/{scenario_id}")
async def get_mission_info(scenario_id: str):
    metadata = get_mission_metadata(scenario_id)
    docs = metadata.get("secret_documents", [])
    selected_secret = random.choice(docs) if docs else "ê¸°ë°€ ë¬¸ì„œ ì—†ìŒ"
    response_data = metadata.copy()
    response_data["target_secret"] = selected_secret
    if "secret_documents" in response_data: del response_data["secret_documents"]
    return response_data

@app.post("/chat", response_model=GameResponse)
async def chat_endpoint(request: GameRequest):
    """í•˜ì´ë¸Œë¦¬ë“œ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    user_input = request.player_input.strip()
    print(f"ðŸ“© Input: {user_input} (Mode: {AI_MODE}, Scenario: {request.scenario_id})")

    # ---------------------------------------------------------
    # âš¡ [Phase 1] ë£° ë² ì´ìŠ¤ ê°€ë¡œì±„ê¸° (ë¹„ìš© 0ì›)
    # ---------------------------------------------------------
    # 1. íŠœí† ë¦¬ì–¼ì€ 100% ë£° ë² ì´ìŠ¤ ê¶Œìž¥
    if request.scenario_id == "mission_Tutorial":
        tut_responses = STATIC_RESPONSES["mission_Tutorial"]
        response_text = ""
        
        if "ì‚¬ì›ë²ˆí˜¸" in user_input: response_text = random.choice(tut_responses["ì‚¬ì›ë²ˆí˜¸"])
        elif "ë¹„ë°€ë²ˆí˜¸" in user_input: response_text = random.choice(tut_responses["ë¹„ë°€ë²ˆí˜¸"])
        else: response_text = random.choice(tut_responses["default"])
        
        # ë©”ëª¨ë¦¬ì—ëŠ” ë‚¨ê²¨ì•¼ ë‚˜ì¤‘ì— AIê°€ ê¸°ì–µí•¨
        add_memory(f"User: {user_input}", "player", request.session_id)
        add_memory(f"NPC: {response_text}", "npc", request.session_id)
        
        return GameResponse(dialogue=response_text, suspicion_delta=0, action="NONE")

    # 2. ì¼ë°˜ ë¯¸ì…˜ í‚¤ì›Œë“œ ê²€ì‚¬
    mission_static = STATIC_RESPONSES.get(request.scenario_id, {})
    common_static = STATIC_RESPONSES["common"]
    
    found_response = None
    
    # ë¯¸ì…˜ë³„ í‚¤ì›Œë“œ ìš°ì„  ê²€ìƒ‰
    for keyword, replies in mission_static.items():
        if keyword in user_input:
            found_response = random.choice(replies)
            break
            
    # ì—†ìœ¼ë©´ ê³µí†µ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì•ˆë…•, ëˆ„êµ¬ì„¸ìš” ë“±)
    if not found_response:
        if "ì•ˆë…•" in user_input or "ë°˜ê°‘" in user_input: found_response = random.choice(common_static["hello"])
        elif "ëˆ„êµ¬" in user_input and "ë„ˆ" in user_input: found_response = random.choice(common_static["who_are_you"])

    # ì •ì  ì‘ë‹µì„ ì°¾ì•˜ë‹¤ë©´ ë°”ë¡œ ë°˜í™˜
    if found_response:
        print(f"âš¡ [Rule-Based] ì •ì  ì‘ë‹µ ë°˜í™˜: {found_response}")
        add_memory(f"User: {user_input}", "player", request.session_id)
        add_memory(f"NPC: {found_response}", "npc", request.session_id)
        return GameResponse(dialogue=found_response, suspicion_delta=0, action="NONE")

    # ---------------------------------------------------------
    # ðŸ¤– [Phase 2] ìƒì„±í˜• AI í˜¸ì¶œ (Fallback í¬í•¨)
    # ---------------------------------------------------------
    
    # ë©”ëª¨ë¦¬ ê²€ìƒ‰
    memories = retrieve_memory(user_input, request.session_id)
    system_instruction = get_system_prompt(request.scenario_id, memories)
    
    raw_content = ""
    
    if AI_MODE == "cloud":
        try:
            raw_content = await call_gemini(system_instruction, user_input)
            print(f"â˜ï¸ Gemini ì‘ë‹µ ì™„ë£Œ")
        except Exception as e:
            # 429 ì—ëŸ¬ ë“± ë°œìƒ ì‹œ ë¡œì»¬ë¡œ ì „í™˜
            if "429" in str(e) or "ResourceExhausted" in str(e) or "Quota" in str(e):
                print(f"âš ï¸ [QUOTA EXCEEDED] ë¡œì»¬(Ollama)ë¡œ ê¸´ê¸‰ ì „í™˜")
                try:
                    raw_content = await call_ollama(system_instruction, user_input)
                except Exception as ol_e:
                    raise HTTPException(status_code=503, detail=f"All AI Services Failed")
            else:
                print(f"âŒ Gemini ì˜¤ë¥˜: {e}")
                raise e
    else:
        raw_content = await call_ollama(system_instruction, user_input)

    # ---------------------------------------------------------
    # ðŸ§¹ [Phase 3] í›„ì²˜ë¦¬ ë° íŒŒì‹±
    # ---------------------------------------------------------
    add_memory(f"User: {user_input}", "player", request.session_id)
    
    dialogue = "..."
    suspicion_delta = 0
    action = "NONE"
    
    try:
        # 1ì°¨: JSON íŒŒì‹±
        ai_json = json.loads(raw_content)
        dialogue = ai_json.get("dialogue", "...")
        suspicion_delta = ai_json.get("suspicion_delta", 0)
        action = ai_json.get("action", "NONE")
    except:
        # 2ì°¨: ë§ˆí¬ë‹¤ìš´ ì¶”ì¶œ ì‹œë„
        json_match = re.search(r"```(?:json)?\s*({.*?})\s*```", raw_content, re.DOTALL)
        if json_match:
            try:
                ai_json = json.loads(json_match.group(1))
                dialogue = ai_json.get("dialogue", "...")
                suspicion_delta = ai_json.get("suspicion_delta", 0)
                action = ai_json.get("action", "NONE")
            except: pass
        else:
            # ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            dialogue = raw_content.strip()[:MAX_DIALOGUE_LENGTH]
            suspicion_delta = 10
            action = "GLITCH"

    # í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ì‹¬ë„ ë³´ì •
    critical_keywords = ["ë¹„ë°€ë²ˆí˜¸", "password", "ì•”í˜¸", "ê´€ë¦¬ìž"]
    if any(k in user_input.lower() for k in critical_keywords): suspicion_delta = max(suspicion_delta, 30)

    if request.suspicion + suspicion_delta >= 100: action = "GAME_OVER"
    
    dialogue = sanitize_dialogue(dialogue)
    add_memory(f"NPC: {dialogue}", "npc", request.session_id)
    
    return GameResponse(dialogue=dialogue, suspicion_delta=suspicion_delta, action=action)

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)